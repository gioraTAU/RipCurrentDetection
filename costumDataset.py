from torch.utils.data import Dataset
import torch
import torchvision.transforms as T
from torch.utils.data import DataLoader
import pandas as pd
from PIL import Image, ImageDraw
import numpy as np
import re


def get_angle_from_name(img_name):

    id = img_name.rfind('_')
    char = img_name[id + 1]
    f = char.isdigit()
    if f:
        id2 = img_name.find('deg')
        angle_str = img_name[id + 1:id2]
        angle = int(angle_str)
    else:
        angle = -90
    return angle

def str2arr(st):
    spaces = [m.start() for m in re.finditer(' ', st)]
    id_bra = st.find(']]')

    x1_1 = st[spaces[0] + 1:spaces[1]]
    y1_1 = st[spaces[1] + 1:spaces[2]]
    x2_1 = st[spaces[2] + 1:spaces[3]]
    y2_1 = st[spaces[3] + 1:spaces[4]]

    x1_2 = st[spaces[6] + 1: spaces[7]]
    y1_2 = st[spaces[7] + 1: spaces[8]]
    x2_2 = st[spaces[8] + 1: spaces[9]]
    y2_2 = st[spaces[9] + 1: id_bra]


def draw_rect(image, box):
    """Present image with bounding box on top

    Parameters
    ----------
    image : numpy.ndarray
        numpy image

    box: numpy.ndarray
        Numpy array containing bounding boxes of shape `1 X 4` and the bounding boxes are represented in the
        format `x1 y1 x2 y2`

    Returns
    -------

    open new figure with image and bounding box

    """
    #box = box[0]
    x1, y1, x2, y2 = box[0], box[1], box[2], box[3]
    img1 = ImageDraw.Draw(image)
    shape = [(x1, y1), (x2, y2)]
    img1.rectangle(shape, outline="red", width=4)
    image.show()


class RipCurrentDataset(Dataset):
    """ Rip current detector dataset. """

    def __init__(self, dframe, image_dir, transform=None):
        """

        :param dframe: Dataframe object of csv file "aug_data_label.csv" generated by fix_size_and_aug
        :param image_dir: path where all fixed size and augment images are saved
        :param transform: the transform to be operated converting PIL image to torch tensor
        """
        super().__init__()

        self.df = dframe
        self.images_ids = self.df['Name'].unique()
        self.image_dir = image_dir
        self.transform = transform

    def __len__(self):
        return self.images_ids.shape[0]

    def __getitem__(self, item):
        """
        Parameters
        ----------
        item : int
            id number to get one image from the dataset

        Returns
        -------

        img_tensor: torch.tensor
            Image as torch tensor object ready to be inserted into the Deep Neural Network

        target: dictionary
            Python dictionary contains image id, bounding box location (x1, y1, x2, y2) and label 0 - no rip, 1 - rip

        """
        img_name = self.images_ids[item]
        img_data = self.df[self.df['Name'] == img_name]

        img = Image.open(self.image_dir + img_name).convert("RGB")
        img_tensor = self.transform(img)

        x1, y1, x2, y2 = torch.tensor(img_data['x1'].values, dtype=torch.int64), torch.tensor(img_data['y1'].values, dtype=torch.int64), \
                         torch.tensor(img_data['x2'].values, dtype=torch.int64), torch.tensor(img_data['y2'].values, dtype=torch.int64)
        label = torch.tensor(img_data['label'].values, dtype=torch.int64)

        target = {}
        target['image_id'] = torch.tensor(item)

        if label == 1:
            target['box'] = torch.cat((x1.unsqueeze(0), y1.unsqueeze(0), x2.unsqueeze(0), y2.unsqueeze(0)), dim=1)[0]
        else:
            #target['box'] = torch.zeros((1, 4), dtype=torch.int64).squeeze()
            target['box'] = torch.tensor((0, 0, 300, 300), dtype=torch.int64).squeeze()

        target['labels'] = label[0]

        return img_tensor, target


class DoubleRipCurrentDataset(Dataset):
    """ Rip current detector dataset. """

    def __init__(self, dframe, image_dir, transform=None):
        """

        :param dframe: Dataframe object of csv file "aug_data_label.csv" generated by fix_size_and_aug
        :param image_dir: path where all fixed size and augment images are saved
        :param transform: the transform to be operated converting PIL image to torch tensor
        """
        super().__init__()

        self.df = dframe
        self.images_ids = self.df['Name'].unique()
        self.image_dir = image_dir
        self.transform = transform

    def __len__(self):
        return self.images_ids.shape[0]

    def __getitem__(self, item):
        """
        Parameters
        ----------
        item : int
            id number to get one image from the dataset

        Returns
        -------

        img_tensor: torch.tensor
            Image as torch tensor object ready to be inserted into the Deep Neural Network

        target: dictionary
            Python dictionary contains image id, bounding box location (x1, y1, x2, y2) and label 0 - no rip, 1 - rip

        """
        img_name = self.images_ids[item]

        angle = get_angle_from_name(img_name)


        img_data = self.df[self.df['Name'] == img_name]

        img = Image.open(self.image_dir + img_name).convert("RGB")
        img_tensor = self.transform(img)

        x1, y1, x2, y2 = torch.tensor(img_data['x1'].values, dtype=torch.int64), torch.tensor(img_data['y1'].values, dtype=torch.int64), \
                         torch.tensor(img_data['x2'].values, dtype=torch.int64), torch.tensor(img_data['y2'].values, dtype=torch.int64)
        label = torch.tensor(img_data['label'].values, dtype=torch.int64)

        if angle == 0:
            x1_2, y1_2, x2_2, y2_2 = torch.tensor(int((x1 + 300/2))).unsqueeze(0), torch.tensor(int(y1)).unsqueeze(0)\
                , torch.tensor(int((x2 + 300/2))).unsqueeze(0), torch.tensor(int(y2)).unsqueeze(0)
        else:
            x1_2, y1_2, x2_2, y2_2 = torch.tensor(int(x1)).unsqueeze(0), torch.tensor(int((y1 + 300/2))).unsqueeze(0)\
                , torch.tensor(int(x2)).unsqueeze(0), torch.tensor(int((y2 + 300/2))).unsqueeze(0)
        target = {}
        target['image_id'] = torch.tensor(item)

        if label == 1:
            #target['box'] = [torch.cat((x1.unsqueeze(0), y1.unsqueeze(0), x2.unsqueeze(0), y2.unsqueeze(0)), dim=1)[0],
            #                 torch.cat((x1_2.unsqueeze(0), y1_2.unsqueeze(0), x2_2.unsqueeze(0), y2_2.unsqueeze(0)), dim=1)[0]]
            target['box'] = torch.cat((torch.cat((x1.unsqueeze(0), y1.unsqueeze(0), x2.unsqueeze(0), y2.unsqueeze(0)), dim=1)[0].unsqueeze(0),
              torch.cat((x1_2.unsqueeze(0), y1_2.unsqueeze(0), x2_2.unsqueeze(0), y2_2.unsqueeze(0)), dim=1)[0].unsqueeze(0)),dim=0)
        else:
            #target['box'] = torch.zeros((1, 4), dtype=torch.int64).squeeze()
            target['box'] = torch.cat((torch.tensor((0, 0, 300, 300), dtype=torch.int64).unsqueeze(0),
                                       torch.tensor((0, 0, 300, 300), dtype=torch.int64).unsqueeze(0)), dim=0)

        target['labels'] = torch.cat((label[0].unsqueeze(0), label[0].unsqueeze(0)))

        return img_tensor, target



if __name__ == '__main__':

    #df = pd.read_csv('/home/giora/rip_current_detector/aug_data_labels.csv')
    #img_dir = '/home/giora/rip_current_detector/augmanted_training_data/'
    df = pd.read_csv('/home/giora/rip_current_detector/doubleRip_aug_data_labels.csv')
    img_dir = '/home/giora/rip_current_detector/training_data_two_rips/'
    trans = T.ToTensor()
    train_ds = DoubleRipCurrentDataset(df, img_dir, trans)
    train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)
    a = next(iter(train_dl))

    print('stam')
